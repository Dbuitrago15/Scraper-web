services:
  redis:
    image: redis:alpine
    container_name: scraper_redis
    ports:
      - "6389:6389"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  api:
    build: 
      context: .
      target: production
    container_name: scraper_api
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - APP_MODE=api
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PORT=3000
      - MAX_BROWSER_INSTANCES=3
      - WORKER_CONCURRENCY=3
      - LOG_LEVEL=info
    depends_on:
      redis:
        condition: service_healthy
    command: ["node", "src/index.js"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    volumes:
      - /dev/shm:/dev/shm

  worker:
    build: 
      context: .
      target: production
    deploy:
      replicas: 2  # Reduced to 2 workers for better stability
    environment:
      - NODE_ENV=production
      - APP_MODE=worker
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MAX_BROWSER_INSTANCES=3  # Reduced for stability
      - WORKER_CONCURRENCY=3     # Reduced for better success rate
      - LOG_LEVEL=info
    depends_on:
      redis:
        condition: service_healthy
    command: ["node", "src/index.js"]
    restart: unless-stopped
    volumes:
      - /dev/shm:/dev/shm
    # Resource limits to prevent overload
    mem_limit: 2g
    cpus: 1.5

volumes:
  redis_data: